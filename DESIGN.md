LazyReader
Authored By: Ayan Gupta, Jonathan Pi, Tony Choi

Project Overview: 
LazyReader is a program that determines the difficulty level of words in a sentence and replaces said word with an easier to understand synonym. Difficulty is determined by where the specified word stands in terms of the most commonly referenced words in the English language. Difficulty is set on an exponential scale with more words being considered difficult than easy. The user can set the Difficulty scale by selecting the number of container levels they would like the words to be classified into. If a user specifies there to be 5 containers, all the words will be split on an exponential scale with container 1 having the most used words but also the least number of words. Container 4 will contain difficult words and the greatest number of words. The last container, or in this case container 5, is always reserved for words that are not contained in the referenced list of most used words. 
The program utilizes Apache OpenNLP, WordNet, and Apache Evo Inflector APIs. OpenNLP is used for Part of Speech (POS) categorization of words in sentences. Utilizing this data, we are able to determine which words are nouns, verbs, as well as if the word is plural or singular. In the current version of LazyReader, only nouns are replaced. WordNet is utilized to find synonyms of words in the English language. Apache Evo Inflector is used to convert words in singular tense to plural tense based on the classification provided by OpenNLP. 

LazyReader Class: 
The LazyReader class is the main class that will simplify a sentence. LazyReader will use OpenNLP to first tokenize a sentence that is passed to it. It will determine the POS of each word and provide the POS tags of each word in a separate array. WordNet classifies the POS words with great details. However, for out implementation, we are only interested if the word is a noun, verb, etc. Utilizing the POS tags array, we extract just the first letter of each tag as that determines the simple POS. Using this data, we determine which words are nouns and need to be checked for difficulty. As of now, we are only replacing nouns since verb replacement will require correct identification verb tense and application of said verb tense to the synonym replacement.  
LazyReader utilizes the POS classification provided by OpenNLP to determine the difficulty level of each noun in the sentence. The word will be replaced if its difficulty classification is above a set amount. To replace a word, synonyms are provided by WordNet. Since multiple synonyms are provided, the synonym that is classified with the least difficulty is used. 

DifficultyClassifier Class: 
The DifficultyClassifier class is utilized to parse data from a .txt file containing a sorted list of the most commonly used words in the English language and classify them. Difficulty is determined by the number of containers specified by the user. If the user does not define the container count, the program will default to 10 containers. Classification occurs on an exponential scale. The first container will contain 2x words, second container will container 4x words, third container will contain 8x words, and so on. The last container is always reserved for words that are not included in the .txt document with most used words. The classified words are placed into a map where the key is the word and the corresponding value is the classification integer. 

Future Improvements: 
LazyReader has very limited functionality in this release version. Currently there is not support for word replacement other than nouns. The main reasoning behind this is POS like verbs require us to identify and then apply the correct verb tense to the replacement word. While OpenNLP does identity the verb tense, we did not have time to implement a verb tense modifier for the synonym word. OpenNLP does not container functionality to do this. However, the Stanford University NLP API contains functionality that allows for verb tense conversion that can be utilized in the future. Additionally, future releases of this program will include a difficulty test functionality where a user will be able to take a short exam with words to determine their current reading level. Utilizing this data, we will be able to select appropriate words to replace based on the user. This functionality has been abstracted, implementation did not occur due to time restrictions. 
